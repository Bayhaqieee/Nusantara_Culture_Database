{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 928 images belonging to 29 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 232 images belonging to 29 classes.\n"
     ]
    }
   ],
   "source": [
    "# Parameter\n",
    "IMG_SIZE = (224,224)  # Ukuran gambar untuk MobileNetV2\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 35\n",
    "LEARNING_RATE = 0.001\n",
    "FINE_TUNE_EPOCHS = 20  # Tambahan epoch untuk fine-tuning\n",
    "FINE_TUNE_LR = 1e-5    # Learning rate untuk fine-tuning\n",
    "\n",
    "# Direktori dataset\n",
    "train_dir = \"train_batik\"\n",
    "test_dir = \"test_batik_2\"\n",
    "\n",
    "# Augmentasi Data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "\n",
    "# Generator Data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "# Informasi jumlah kelas\n",
    "num_classes = len(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.0590 - loss: 3.7042 - val_accuracy: 0.2845 - val_loss: 2.6953 - learning_rate: 0.0010\n",
      "Epoch 2/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.2982 - loss: 2.5821 - val_accuracy: 0.4267 - val_loss: 2.1454 - learning_rate: 0.0010\n",
      "Epoch 3/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.4379 - loss: 1.9871 - val_accuracy: 0.4526 - val_loss: 1.8724 - learning_rate: 0.0010\n",
      "Epoch 4/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5125 - loss: 1.6049 - val_accuracy: 0.5302 - val_loss: 1.6529 - learning_rate: 0.0010\n",
      "Epoch 5/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.5875 - loss: 1.3623 - val_accuracy: 0.5603 - val_loss: 1.5526 - learning_rate: 0.0010\n",
      "Epoch 6/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.6032 - loss: 1.2228 - val_accuracy: 0.5302 - val_loss: 1.5856 - learning_rate: 0.0010\n",
      "Epoch 7/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.6674 - loss: 1.0990 - val_accuracy: 0.5603 - val_loss: 1.5666 - learning_rate: 0.0010\n",
      "Epoch 8/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.6586 - loss: 1.1204 - val_accuracy: 0.5905 - val_loss: 1.4755 - learning_rate: 0.0010\n",
      "Epoch 9/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.7080 - loss: 0.9439 - val_accuracy: 0.5733 - val_loss: 1.5191 - learning_rate: 0.0010\n",
      "Epoch 10/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.7127 - loss: 0.9417 - val_accuracy: 0.6034 - val_loss: 1.4517 - learning_rate: 0.0010\n",
      "Epoch 11/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - accuracy: 0.7603 - loss: 0.7756 - val_accuracy: 0.5862 - val_loss: 1.5457 - learning_rate: 0.0010\n",
      "Epoch 12/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - accuracy: 0.7536 - loss: 0.8421 - val_accuracy: 0.5776 - val_loss: 1.4857 - learning_rate: 0.0010\n",
      "Epoch 13/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.7329 - loss: 0.8881 - val_accuracy: 0.5776 - val_loss: 1.5163 - learning_rate: 0.0010\n",
      "Epoch 14/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.7922 - loss: 0.6699 - val_accuracy: 0.6121 - val_loss: 1.4472 - learning_rate: 2.0000e-04\n",
      "Epoch 15/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.7944 - loss: 0.6436 - val_accuracy: 0.5905 - val_loss: 1.4201 - learning_rate: 2.0000e-04\n",
      "Epoch 16/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.7982 - loss: 0.6094 - val_accuracy: 0.5905 - val_loss: 1.4506 - learning_rate: 2.0000e-04\n",
      "Epoch 17/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 1s/step - accuracy: 0.8237 - loss: 0.5596 - val_accuracy: 0.6078 - val_loss: 1.4331 - learning_rate: 2.0000e-04\n",
      "Epoch 18/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - accuracy: 0.8165 - loss: 0.5787 - val_accuracy: 0.6164 - val_loss: 1.4269 - learning_rate: 2.0000e-04\n",
      "Epoch 19/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.8065 - loss: 0.5636 - val_accuracy: 0.6121 - val_loss: 1.4226 - learning_rate: 4.0000e-05\n",
      "Epoch 20/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.8429 - loss: 0.5159 - val_accuracy: 0.6164 - val_loss: 1.4141 - learning_rate: 4.0000e-05\n",
      "Epoch 21/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.8108 - loss: 0.5961 - val_accuracy: 0.6164 - val_loss: 1.4148 - learning_rate: 4.0000e-05\n",
      "Epoch 22/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.8114 - loss: 0.5917 - val_accuracy: 0.6121 - val_loss: 1.4177 - learning_rate: 4.0000e-05\n",
      "Epoch 23/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - accuracy: 0.8333 - loss: 0.5667 - val_accuracy: 0.6164 - val_loss: 1.4148 - learning_rate: 4.0000e-05\n",
      "Epoch 24/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - accuracy: 0.8124 - loss: 0.5883 - val_accuracy: 0.6121 - val_loss: 1.4163 - learning_rate: 8.0000e-06\n",
      "Epoch 25/35\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.8194 - loss: 0.5806 - val_accuracy: 0.6164 - val_loss: 1.4166 - learning_rate: 8.0000e-06\n"
     ]
    }
   ],
   "source": [
    "# Model Transfer Learning\n",
    "base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Bekukan layer pada model dasar untuk transfer learning\n",
    "\n",
    "# Tambahkan lapisan khusus\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)  # Dropout untuk mencegah overfitting\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "predictions = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "# Buat model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Kompilasi model untuk transfer learning\n",
    "model.compile(optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Callback\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=3, min_lr=1e-6)\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "\n",
    "# Pelatihan awal (transfer learning)\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[reduce_lr, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"mobilenet_batik_oldcode.h5\") # Menyimpan model ke file my_model.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning\n",
    "# Buka beberapa lapisan terakhir dari base model\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-20]:  # Bekukan semua kecuali 20 lapisan terakhir\n",
    "    layer.trainable = False\n",
    "\n",
    "# Kompilasi ulang model dengan learning rate yang lebih kecil\n",
    "model.compile(optimizer=Adam(learning_rate=FINE_TUNE_LR),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Fine-tuning model\n",
    "history_fine_tune = model.fit(\n",
    "    train_generator,\n",
    "    epochs=FINE_TUNE_EPOCHS,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[reduce_lr, early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluasi model\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "model.save(\"my_model.h5\")  # Menyimpan model ke file my_model.h5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
